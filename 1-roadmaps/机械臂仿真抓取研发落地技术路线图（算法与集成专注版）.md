# æœºæ¢°è‡‚ä»¿çœŸæŠ“å–ç ”å‘è½åœ°æŠ€æœ¯è·¯çº¿å›¾ï¼ˆç®—æ³•ä¸é›†æˆä¸“æ³¨ç‰ˆï¼‰

**æ–‡æ¡£ç‰ˆæœ¬ï¼š** v1.0  
**åˆ›å»ºæ—¥æœŸï¼š** 2025-10-09  
**é€‚ç”¨åœºæ™¯ï¼š** 3Cåˆ¶é€ é¢†åŸŸæœºæ¢°è‡‚æŠ“å–ç³»ç»Ÿç ”å‘  
**æŠ€æœ¯ç‰¹ç‚¹ï¼š** å¼€æºæŠ€æœ¯æ ˆ + å¼€ç®±å³ç”¨èµ„æº + ç®—æ³•èšç„¦ + å¯æ‰©å±•æ¶æ„

---

## ğŸ“‹ æ–‡æ¡£ç›®æ ‡

æœ¬è·¯çº¿å›¾æ—¨åœ¨ä¸ºæœºæ¢°è‡‚æŠ“å–ç ”å‘å›¢é˜Ÿæä¾›ï¼š

1. **å¼€ç®±å³ç”¨çš„ä»¿çœŸèµ„æº** - 3Cé›¶ä»¶æ¨¡å‹ + æœºæ¢°è‡‚URDF + é¢„é…ç½®åœºæ™¯
2. **ç³»ç»ŸåŒ–ç®—æ³•ç ”å‘æµç¨‹** - ä»æ„ŸçŸ¥åˆ°æ§åˆ¶çš„å®Œæ•´pipeline
3. **é«˜æ•ˆçš„ä»¿çœŸé›†æˆæ–¹æ¡ˆ** - ç«¯åˆ°ç«¯å·¥ä½œæµ + è°ƒè¯•å·¥å…·é“¾
4. **å¼€æºå¯æ‰©å±•æ¶æ„** - æ¨¡å—åŒ–è®¾è®¡ + æ”¯æŒåç»­åŠŸèƒ½æ‰©å±•

**æ ¸å¿ƒç†å¿µï¼š** è®©å›¢é˜Ÿèšç„¦äºç®—æ³•åˆ›æ–°å’Œç³»ç»Ÿä¼˜åŒ–ï¼Œè€ŒéåŸºç¡€ç¯å¢ƒæ­å»ºã€‚

---

## ğŸ¯ ç¬¬ä¸€éƒ¨åˆ†ï¼šå¼€ç®±å³ç”¨çš„ä»¿çœŸèµ„æºæ¸…å•

### 1.1 æœºæ¢°è‡‚ä»¿çœŸèµ„æºï¼ˆReady-to-Useï¼‰

#### 1.1.1 æ¨èæœºæ¢°è‡‚å‹å·åŠURDFèµ„æº

| æœºæ¢°è‡‚å‹å· | å¼€æºURDFä»“åº“ | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|-----------|-------------|------|---------|
| **Universal Robots UR5/UR5e** | `github.com/ros-industrial/universal_robot`<br>`github.com/UniversalRobots/Universal_Robots_ROS2_Description` | â€¢ å·¥ä¸šæ ‡å‡†<br>â€¢ é‡å¤ç²¾åº¦Â±0.03mm<br>â€¢ ç¤¾åŒºæ”¯æŒæœ€å¥½ | é«˜ç²¾åº¦3Cè£…é…<br>PCBæ“ä½œ |
| **Franka Emika Panda** | `github.com/frankaemika/franka_ros`<br>`github.com/frankaemika/franka_ros2` | â€¢ 7è‡ªç”±åº¦<br>â€¢ åŠ›åé¦ˆä¼˜ç§€<br>â€¢ å­¦æœ¯ç•Œé¦–é€‰ | æŸ”æ€§æŠ“å–<br>æ¥è§¦åŠ›æ•æ„Ÿä»»åŠ¡ |
| **AUBO i5** | `github.com/aubo-robot/aubo_robot` | â€¢ å›½äº§æ–¹æ¡ˆ<br>â€¢ æ€§ä»·æ¯”é«˜<br>â€¢ é€‚åˆä¸­å°å›¢é˜Ÿ | ä¸€èˆ¬ç²¾åº¦æŠ“å–<br>æ•™è‚²ç ”å‘ |
| **Kinova Gen3** | `github.com/Kinovarobotics/ros_kortex` | â€¢ 7è‡ªç”±åº¦<br>â€¢ çµæ´»æ€§é«˜<br>â€¢ é€‚åˆå¤æ‚å§¿æ€ | ç‹­å°ç©ºé—´æŠ“å–<br>å¤šè§’åº¦æ“ä½œ |

**å¿«é€Ÿå¯åŠ¨å‘½ä»¤ï¼š**

```bash
# UR5 (ROS 2)
git clone https://github.com/UniversalRobots/Universal_Robots_ROS2_Description.git
cd Universal_Robots_ROS2_Description
colcon build

# Franka Panda (ROS 2)
git clone https://github.com/frankaemika/franka_ros2.git
cd franka_ros2
colcon build --cmake-args -DCMAKE_BUILD_TYPE=Release
```

#### 1.1.2 æœ«ç«¯æ‰§è¡Œå™¨ï¼ˆå¤¹çˆªï¼‰èµ„æº

| å¤¹çˆªå‹å· | URDF/æ¨¡å‹èµ„æº | ç‰¹ç‚¹ |
|---------|--------------|------|
| **Robotiq 2F-85** | `github.com/JStech/robotiq_2f_description` | æ ‡å‡†å¹³è¡Œå¤¹çˆªï¼Œé€‚åˆè§„åˆ™é›¶ä»¶ |
| **Robotiq Hand-E** | `github.com/cambel/robotiq` | ç´§å‡‘å‹ï¼Œé€‚åˆç‹­å°ç©ºé—´ |
| **Franka Hand** | åŒ…å«åœ¨`franka_ros`ä¸­ | åŠ›åé¦ˆä¼˜ç§€ï¼Œé€‚åˆæŸ”æ€§æŠ“å– |
| **å¸ç›˜å¤¹çˆªï¼ˆè‡ªå®šä¹‰ï¼‰** | éœ€è‡ªè¡Œå»ºæ¨¡ï¼ˆè§1.3èŠ‚ï¼‰ | é€‚åˆå¹³é¢3Cé›¶ä»¶ï¼ˆPCBã€å±å¹•ï¼‰ |

### 1.2 3Cé›¶ä»¶ä»¿çœŸæ¨¡å‹èµ„æº

#### 1.2.1 ç°æˆç‰©ä½“æ•°æ®é›†ï¼ˆå¯ç›´æ¥ä½¿ç”¨ï¼‰

| æ•°æ®é›†åç§° | è§„æ¨¡ | ä¸‹è½½åœ°å€ | æ ¼å¼ | 3Cç›¸å…³æ€§ |
|-----------|------|---------|------|---------|
| **YCB Objects** | 77ä¸ªæ—¥å¸¸ç‰©ä½“ | `ycb-benchmarks.s3-website-us-east-1.amazonaws.com` | OBJ, STL, URDF | â­â­â˜† (éƒ¨åˆ†ç”µå­äº§å“) |
| **GraspNet-1B Objects** | 88ä¸ªç‰©ä½“ | `graspnet.net/datasets.html` | OBJ, PLY | â­â­â­ (åŒ…å«ç”µå­é›¶ä»¶) |
| **DexGraspNet** | 5355ä¸ªç‰©ä½“ | `pku-epic.github.io/DexGraspNet` | URDF, OBJ | â­â­â­â­ (å¤§é‡å°é›¶ä»¶) |
| **Google Scanned Objects** | 1032ä¸ªç‰©ä½“ | `fuel.gazebosim.org/GoogleResearch/GSODataset` | OBJ, SDF | â­â­â­ (å¤šæ ·æ€§é«˜) |
| **OmniObject3D** | 6000+ç‰©ä½“ | `omniobject3d.github.io` | OBJ, USD | â­â­â­â­ (ç²¾åº¦é«˜) |

**å¿«é€Ÿä¸‹è½½è„šæœ¬ï¼š**

```bash
# YCB Objects (ç¤ºä¾‹ï¼šä¸‹è½½å‰10ä¸ª)
mkdir -p ~/grasp_resources/ycb_objects
cd ~/grasp_resources/ycb_objects
for i in {001..010}; do
    wget http://ycb-benchmarks.s3-website-us-east-1.amazonaws.com/data/objects/${i}_*/google_16k/textured.obj
done

# GraspNet-1B Objects (éœ€å…ˆæ³¨å†Œ)
# è®¿é—® https://graspnet.net æ³¨å†Œåè·å–ä¸‹è½½é“¾æ¥

# Google Scanned Objects (é€šè¿‡Fuelä¸‹è½½)
ign fuel download -u https://fuel.gazebosim.org/1.0/GoogleResearch/models/Google_Scanned_Objects
```

#### 1.2.2 ä¸“ç”¨3Cé›¶ä»¶æ¨¡å‹åº“

ç”±äºä¸“ç”¨3Cé›¶ä»¶æ¨¡å‹è¾ƒå°‘ï¼Œæ¨èä»¥ä¸‹è·å–æ–¹å¼ï¼š

**æ–¹æ¡ˆAï¼šå¼€æºCADåº“**

| èµ„æºç½‘ç«™ | å†…å®¹ | è®¿é—®æ–¹å¼ |
|---------|------|---------|
| **GrabCAD** | SMTå…ƒä»¶ã€PCBæ¿ã€è¿æ¥å™¨ | `grabcad.com/library` (å…è´¹æ³¨å†Œ) |
| **Thingiverse** | ç”µå­é›¶ä»¶3Dæ‰“å°æ¨¡å‹ | `thingiverse.com` (æœç´¢"SMT", "PCB") |
| **TraceParts** | å·¥ä¸šæ ‡å‡†é›¶ä»¶åº“ | `traceparts.com` (éœ€ä¼ä¸šè´¦å·) |

**æ–¹æ¡ˆBï¼šè‡ªåŠ¨ç”Ÿæˆå‚æ•°åŒ–æ¨¡å‹ï¼ˆæ¨èï¼‰**

ä½¿ç”¨OpenSCADæˆ–FreeCADç”Ÿæˆæ ‡å‡†3Cé›¶ä»¶ï¼š

```python
# ç¤ºä¾‹ï¼šç”Ÿæˆ0402 SMTèŠ¯ç‰‡æ¨¡å‹ï¼ˆPython + trimeshï¼‰
import trimesh
import numpy as np

def generate_smt_0402():
    """ç”Ÿæˆ0402è´´ç‰‡ç”µé˜»æ¨¡å‹ (1.0mm x 0.5mm x 0.35mm)"""
    # å°ºå¯¸ï¼ˆå•ä½ï¼šç±³ï¼‰
    length, width, height = 0.001, 0.0005, 0.00035
    
    # åˆ›å»ºbox mesh
    box = trimesh.creation.box(extents=[length, width, height])
    
    # è®¾ç½®ç‰©ç†å±æ€§
    box.density = 1600  # kg/mÂ³ (é™¶ç“·å¯†åº¦)
    
    # å¯¼å‡ºä¸ºURDF
    box.export('smt_0402.obj')
    
    # ç”ŸæˆURDFæ–‡ä»¶
    urdf_template = f"""
    <robot name="smt_0402">
      <link name="base_link">
        <visual>
          <geometry>
            <mesh filename="smt_0402.obj" scale="1 1 1"/>
          </geometry>
          <material name="black">
            <color rgba="0.1 0.1 0.1 1"/>
          </material>
        </visual>
        <collision>
          <geometry>
            <box size="{length} {width} {height}"/>
          </geometry>
        </collision>
        <inertial>
          <mass value="{box.mass}"/>
          <inertia ixx="1e-8" ixy="0" ixz="0" iyy="1e-8" iyz="0" izz="1e-8"/>
        </inertial>
      </link>
    </robot>
    """
    
    with open('smt_0402.urdf', 'w') as f:
        f.write(urdf_template)
    
    return box

# æ‰¹é‡ç”Ÿæˆå¸¸è§SMTå°ºå¯¸
smt_sizes = {
    '0201': (0.0006, 0.0003, 0.00026),
    '0402': (0.001, 0.0005, 0.00035),
    '0603': (0.0016, 0.0008, 0.00045),
    '0805': (0.002, 0.00125, 0.0006),
    '1206': (0.0032, 0.0016, 0.0006)
}

for name, dims in smt_sizes.items():
    print(f"Generating {name}...")
    # è°ƒæ•´å°ºå¯¸å‚æ•°ç”Ÿæˆ
```

**æ–¹æ¡ˆCï¼š3Dæ‰«æç°æœ‰é›¶ä»¶**

å·¥å…·æ¨èï¼š
- **Intel RealSense D435i** + **Open3D** - ä½æˆæœ¬æ‰«ææ–¹æ¡ˆ
- **Artec Eva** - ä¸“ä¸šçº§æ‰«æä»ªï¼ˆé«˜ç²¾åº¦ï¼‰

```python
# Open3Dæ‰«æåå¤„ç†ç¤ºä¾‹
import open3d as o3d

# è¯»å–ç‚¹äº‘
pcd = o3d.io.read_point_cloud("scanned_component.ply")

# é™å™ª
pcd = pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=2.0)[0]

# ç½‘æ ¼é‡å»º
mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd, depth=9)

# ç®€åŒ–meshï¼ˆå‡å°‘ä¸‰è§’å½¢æ•°é‡ï¼‰
mesh = mesh.simplify_quadric_decimation(target_number_of_triangles=5000)

# å¯¼å‡º
o3d.io.write_triangle_mesh("component.obj", mesh)
```

### 1.3 é¢„é…ç½®ä»¿çœŸåœºæ™¯

#### 1.3.1 Isaac Labåœºæ™¯ï¼ˆæ¨èï¼‰

**Isaac Lab** æ˜¯NVIDIAå¼€æºçš„è½»é‡çº§ä»¿çœŸæ¡†æ¶ï¼ŒåŸºäºIsaac Simæ„å»ºã€‚

**ä¼˜åŠ¿ï¼š**
- âœ… GPUåŠ é€Ÿç‰©ç†ä»¿çœŸï¼ˆ16K+ å¹¶è¡Œç¯å¢ƒï¼‰
- âœ… RTXå…‰çº¿è¿½è¸ªï¼ˆé«˜ç²¾åº¦è§†è§‰ä¼ æ„Ÿå™¨ï¼‰
- âœ… å†…ç½®å¼ºåŒ–å­¦ä¹ æ¥å£
- âœ… å®Œå…¨å…è´¹å¼€æº

**å®‰è£…ï¼š**

```bash
# 1. å®‰è£…Isaac Sim (éœ€NVIDIA GPU)
# ä¸‹è½½ï¼šhttps://developer.nvidia.com/isaac-sim
# æˆ–ä½¿ç”¨Dockerï¼š
docker pull nvcr.io/nvidia/isaac-sim:2023.1.1

# 2. å®‰è£…Isaac Lab
git clone https://github.com/isaac-sim/IsaacLab.git
cd IsaacLab
./isaaclab.sh --install

# 3. æµ‹è¯•å®‰è£…
./isaaclab.sh -p source/standalone/tutorials/00_sim/create_empty.py
```

**é¢„é…ç½®æŠ“å–åœºæ™¯ï¼š**

Isaac Labæä¾›çš„ç°æˆåœºæ™¯ï¼š

| åœºæ™¯åç§° | è·¯å¾„ | æè¿° |
|---------|------|------|
| **FrankaæŠ“å–åœºæ™¯** | `source/standalone/environments/manipulation/reach` | Frankaæœºæ¢°è‡‚åˆ°è¾¾ç›®æ ‡ç‚¹ |
| **ç‰©ä½“æŠ“å–åœºæ™¯** | `source/standalone/environments/manipulation/lift` | æŠ“å–å¹¶æå‡ç‰©ä½“ |
| **Bin Picking** | `source/extensions/omni.isaac.lab_tasks/manipulation/inhand` | æ–™ç®±æ‹£é€‰åœºæ™¯ |

**è‡ªå®šä¹‰3Cåœºæ™¯ç¤ºä¾‹ï¼š**

```python
# åˆ›å»º3Cé›¶ä»¶æŠ“å–åœºæ™¯
# ä¿å­˜ä¸ºï¼šIsaacLab/source/standalone/custom/smt_grasping.py

import torch
from omni.isaac.lab.app import AppLauncher

# å¯åŠ¨ä»¿çœŸ
app_launcher = AppLauncher(headless=False)
simulation_app = app_launcher.app

from omni.isaac.lab.assets import Articulation, RigidObject
from omni.isaac.lab.sim import SimulationContext
import omni.isaac.lab.sim as sim_utils

# åˆ›å»ºåœºæ™¯
class SMTGraspingScene:
    def __init__(self):
        # 1. åŠ è½½æœºæ¢°è‡‚
        self.robot = Articulation(
            prim_path="/World/Robot",
            spawn=sim_utils.UsdFileCfg(
                usd_path="path/to/ur5e.usd",  # ä½¿ç”¨Isaac Simèµ„äº§åº“
                rigid_props=sim_utils.RigidBodyPropertiesCfg(),
            ),
        )
        
        # 2. åŠ è½½å·¥ä½œå°
        self.table = RigidObject(
            prim_path="/World/Table",
            spawn=sim_utils.CuboidCfg(
                size=(0.8, 0.8, 0.05),
                visual_material=sim_utils.PreviewSurfaceCfg(diffuse_color=(0.5, 0.5, 0.5)),
            ),
        )
        
        # 3. æ‰¹é‡ç”ŸæˆSMTé›¶ä»¶ï¼ˆæ”¯æŒGPUå¹¶è¡Œï¼‰
        self.num_components = 100
        self.components = RigidObject(
            prim_path="/World/Components/Component",
            spawn=sim_utils.UsdFileCfg(
                usd_path="path/to/smt_0402.usd",
                rigid_props=sim_utils.RigidBodyPropertiesCfg(
                    rigid_body_enabled=True,
                    mass=0.0001,  # 0.1g
                ),
            ),
            init_state=RigidObject.InitialStateCfg(
                pos=self._generate_random_positions(self.num_components),
            ),
        )
        
        # 4. æ·»åŠ RGB-Dç›¸æœº
        self.camera = sim_utils.CameraCfg(
            prim_path="/World/Camera",
            update_period=0.1,
            height=480,
            width=640,
            data_types=["rgb", "distance_to_camera", "normals"],
        )
    
    def _generate_random_positions(self, n):
        """åœ¨å·¥ä½œå°ä¸Šç”Ÿæˆéšæœºä½ç½®"""
        x = torch.rand(n) * 0.6 - 0.3  # [-0.3, 0.3]
        y = torch.rand(n) * 0.6 - 0.3
        z = torch.ones(n) * 0.05  # å·¥ä½œå°ä¸Šæ–¹
        return torch.stack([x, y, z], dim=-1)

# è¿è¡Œåœºæ™¯
if __name__ == "__main__":
    scene = SMTGraspingScene()
    print("3CæŠ“å–åœºæ™¯å·²åŠ è½½ï¼")
```

#### 1.3.2 MuJoCoåœºæ™¯ï¼ˆè½»é‡çº§æ–¹æ¡ˆï¼‰

**MuJoCo** æ˜¯DeepMindå¼€æºçš„ç‰©ç†å¼•æ“ï¼Œé€‚åˆå¿«é€Ÿç®—æ³•åŸå‹ã€‚

**ä¼˜åŠ¿ï¼š**
- âœ… é€Ÿåº¦æå¿«ï¼ˆCPUä¼˜åŒ–ï¼‰
- âœ… æ¥è§¦åŠ›å­¦ç²¾ç¡®
- âœ… æ”¯æŒMJXï¼ˆJAXåŠ é€Ÿç‰ˆï¼Œ1000xå¹¶è¡Œï¼‰

**å®‰è£…ï¼š**

```bash
pip install mujoco
pip install mujoco-mjx  # GPUåŠ é€Ÿç‰ˆ
```

**é¢„é…ç½®åœºæ™¯XMLï¼š**

```xml
<!-- ä¿å­˜ä¸ºï¼šur5_smt_grasping.xml -->
<mujoco model="UR5 SMT Grasping">
  <compiler angle="radian" meshdir="meshes/"/>
  
  <asset>
    <!-- åŠ è½½UR5æ¨¡å‹ -->
    <mesh name="base" file="ur5/base.stl"/>
    <mesh name="shoulder" file="ur5/shoulder.stl"/>
    <mesh name="upperarm" file="ur5/upperarm.stl"/>
    <mesh name="forearm" file="ur5/forearm.stl"/>
    <mesh name="wrist1" file="ur5/wrist1.stl"/>
    <mesh name="wrist2" file="ur5/wrist2.stl"/>
    <mesh name="wrist3" file="ur5/wrist3.stl"/>
    
    <!-- SMTé›¶ä»¶ -->
    <mesh name="smt_0402" file="smt_0402.obj" scale="1 1 1"/>
  </asset>
  
  <worldbody>
    <!-- åœ°é¢ -->
    <geom name="floor" type="plane" size="2 2 0.1" rgba="0.8 0.8 0.8 1"/>
    
    <!-- å·¥ä½œå° -->
    <body name="table" pos="0 0 0">
      <geom name="table_top" type="box" size="0.4 0.4 0.025" rgba="0.5 0.5 0.5 1"/>
    </body>
    
    <!-- UR5æœºæ¢°è‡‚ -->
    <body name="ur5_base" pos="0 0 0.025">
      <geom name="base_geom" type="mesh" mesh="base" rgba="0.7 0.7 0.7 1"/>
      <joint name="shoulder_pan" type="hinge" axis="0 0 1" range="-3.14159 3.14159" damping="1"/>
      
      <!-- ... å…¶ä»–å…³èŠ‚ ... -->
    </body>
    
    <!-- SMTé›¶ä»¶ï¼ˆå¯æ‰¹é‡ç”Ÿæˆï¼‰ -->
    <body name="smt_001" pos="0.1 0.1 0.05">
      <geom name="smt_geom_001" type="mesh" mesh="smt_0402" rgba="0.1 0.1 0.1 1" mass="0.0001"/>
      <joint name="smt_free_001" type="free"/>
    </body>
    
    <!-- ç›¸æœºï¼ˆæ¨¡æ‹ŸRGB-Dï¼‰ -->
    <camera name="workspace_cam" pos="0 -0.5 0.5" xyaxes="1 0 0 0 0.7 0.7"/>
  </worldbody>
  
  <actuator>
    <motor name="shoulder_pan_motor" joint="shoulder_pan" ctrlrange="-2 2"/>
    <!-- ... å…¶ä»–ç”µæœº ... -->
  </actuator>
</mujoco>
```

**åŠ è½½åœºæ™¯ï¼š**

```python
import mujoco
import mujoco.viewer

# åŠ è½½æ¨¡å‹
model = mujoco.MjModel.from_xml_path('ur5_smt_grasping.xml')
data = mujoco.MjData(model)

# å¯åŠ¨å¯è§†åŒ–
with mujoco.viewer.launch_passive(model, data) as viewer:
    while viewer.is_running():
        mujoco.mj_step(model, data)
        viewer.sync()
```

#### 1.3.3 Gazeboåœºæ™¯ï¼ˆROSé›†æˆæœ€ä½³ï¼‰

**Gazebo** é€‚åˆROSç”Ÿæ€ç³»ç»Ÿé›†æˆã€‚

**é¢„é…ç½®åœºæ™¯åŒ…ï¼š**

```bash
# å®‰è£…Gazebo + ROS 2
sudo apt install ros-humble-gazebo-ros-pkgs

# å…‹éš†ç¤ºä¾‹åœºæ™¯
git clone https://github.com/ros-industrial/easy_manipulation_deployment.git
cd easy_manipulation_deployment
colcon build

# å¯åŠ¨3CæŠ“å–åœºæ™¯
ros2 launch emd_grasp_demo grasp_demo.launch.py
```

### 1.4 è§†è§‰ä¼ æ„Ÿå™¨ä»¿çœŸ

#### 1.4.1 RGB-Dç›¸æœºé…ç½®

| çœŸå®ç¡¬ä»¶ | ä»¿çœŸç­‰æ•ˆé…ç½® | Isaac Sim | Gazebo |
|---------|------------|----------|--------|
| Intel RealSense D435i | æ·±åº¦èŒƒå›´: 0.3-3m<br>åˆ†è¾¨ç‡: 1280x720 | âœ… å†…ç½®æ”¯æŒ | âœ… `gazebo_ros_camera` |
| Azure Kinect | æ·±åº¦èŒƒå›´: 0.5-5m<br>åˆ†è¾¨ç‡: 1024x1024 | âœ… è‡ªå®šä¹‰é…ç½® | âœ… æ’ä»¶æ”¯æŒ |
| Zivid 2+ | é«˜ç²¾åº¦ç‚¹äº‘<br>ç²¾åº¦: Â±0.02mm | âœ… é«˜çº§å…‰è¿½ | âš ï¸ éœ€æ‰‹åŠ¨é…ç½® |

**Isaac Simç›¸æœºé…ç½®ï¼š**

```python
from omni.isaac.sensor import Camera

camera_cfg = Camera.CameraCfg(
    prim_path="/World/Camera",
    update_period=0.1,  # 10Hz
    height=720,
    width=1280,
    data_types=["rgb", "distance_to_camera", "instance_segmentation"],
    spawn=sim_utils.PinholeCameraCfg(
        focal_length=1.88,  # RealSense D435iç­‰æ•ˆ
        focus_distance=400.0,
        f_stop=1.8,
        horizontal_aperture=4.8,
        clipping_range=(0.01, 1000.0),
    ),
)
```

**Gazeboç›¸æœºæ’ä»¶ï¼š**

```xml
<gazebo reference="camera_link">
  <sensor name="rgbd_camera" type="depth">
    <update_rate>30</update_rate>
    <camera>
      <horizontal_fov>1.047</horizontal_fov>
      <image>
        <width>1280</width>
        <height>720</height>
        <format>R8G8B8</format>
      </image>
      <clip>
        <near>0.3</near>
        <far>3.0</far>
      </clip>
    </camera>
    <plugin name="camera_controller" filename="libgazebo_ros_camera.so">
      <ros>
        <namespace>/camera</namespace>
        <remapping>image_raw:=rgb/image_raw</remapping>
        <remapping>depth/image_raw:=depth/image_raw</remapping>
      </ros>
    </plugin>
  </sensor>
</gazebo>
```

---

## ğŸ§  ç¬¬äºŒéƒ¨åˆ†ï¼šç®—æ³•ç ”å‘å®Œæ•´æµç¨‹

### 2.1 æ„ŸçŸ¥å±‚ç®—æ³•

#### 2.1.1 ç‰©ä½“æ£€æµ‹ä¸åˆ†å‰²

**æŠ€æœ¯æ ˆé€‰æ‹©ï¼š**

| ä»»åŠ¡ç±»å‹ | æ¨èç®—æ³• | å¼€æºå®ç° | é€Ÿåº¦/ç²¾åº¦ |
|---------|---------|---------|----------|
| 2Dç›®æ ‡æ£€æµ‹ | YOLOv8/v9 | `ultralytics/ultralytics` | âš¡âš¡âš¡ 30ms/å¸§ |
| å®ä¾‹åˆ†å‰² | Mask R-CNN | `matterport/Mask_RCNN` | âš¡âš¡â˜† 80ms/å¸§ |
| 3Dç‚¹äº‘åˆ†å‰² | PointNet++ | `yanx27/Pointnet_Pointnet2_pytorch` | âš¡âš¡â˜† 50ms/ç‚¹äº‘ |
| è¯­ä¹‰åˆ†å‰² | Segment Anything (SAM) | `facebookresearch/segment-anything` | âš¡âš¡â˜† 100ms/å¸§ |

**å®ç°æ­¥éª¤ - ä»¥YOLOv8ä¸ºä¾‹ï¼š**

```bash
# 1. å®‰è£…
pip install ultralytics

# 2. å‡†å¤‡æ•°æ®é›†
# æ•°æ®é›†ç»“æ„ï¼š
# dataset/
#   â”œâ”€â”€ images/
#   â”‚   â”œâ”€â”€ train/
#   â”‚   â””â”€â”€ val/
#   â””â”€â”€ labels/
#       â”œâ”€â”€ train/
#       â””â”€â”€ val/
```

```python
# 3. è®­ç»ƒ3Cé›¶ä»¶æ£€æµ‹æ¨¡å‹
from ultralytics import YOLO

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
model = YOLO('yolov8n.pt')  # nanoç‰ˆæœ¬ï¼Œé€‚åˆè¾¹ç¼˜éƒ¨ç½²

# è®­ç»ƒ
results = model.train(
    data='3c_components.yaml',  # æ•°æ®é›†é…ç½®
    epochs=100,
    imgsz=640,
    batch=16,
    device=0,  # GPU
    project='3c_detection',
    name='smt_detector_v1',
    # é’ˆå¯¹å°ç‰©ä½“ä¼˜åŒ–
    mosaic=0.5,
    mixup=0.1,
    copy_paste=0.1,
)

# 4. å¯¼å‡ºä¸ºONNXï¼ˆåŠ é€Ÿæ¨ç†ï¼‰
model.export(format='onnx', dynamic=True, simplify=True)
```

**æ•°æ®é›†é…ç½®æ–‡ä»¶ï¼ˆ3c_components.yamlï¼‰ï¼š**

```yaml
# æ•°æ®è·¯å¾„
path: ./dataset
train: images/train
val: images/val

# ç±»åˆ«
nc: 10  # ç±»åˆ«æ•°é‡
names:
  0: smt_0402
  1: smt_0603
  2: smt_0805
  3: connector_usb
  4: connector_hdmi
  5: ic_chip_qfn
  6: ic_chip_bga
  7: capacitor_elect
  8: pcb_board
  9: flex_cable
```

#### 2.1.2 6Dä½å§¿ä¼°è®¡

**æ¨èæ–¹æ³•ï¼š**

| æ–¹æ³• | è®ºæ–‡/ä»£ç  | ç²¾åº¦ | é€Ÿåº¦ | é€‚ç”¨åœºæ™¯ |
|------|----------|------|------|---------|
| **PoseCNN** | `yuxng/PoseCNN-PyTorch` | Â±5mm | 20Hz | é€šç”¨ç‰©ä½“ |
| **DenseFusion** | `j96w/DenseFusion` | Â±3mm | 12Hz | ç²¾ç¡®æŠ“å– |
| **GDR-Net** | `THU-DA-6D-Pose-Group/GDR-Net` | Â±2mm | 15Hz | é«˜ç²¾åº¦éœ€æ±‚ |
| **FoundationPose** | `NVlabs/FoundationPose` | Â±1mm | 10Hz | å°‘æ ·æœ¬/æ–°ç‰©ä½“ |

**å®ç°ç¤ºä¾‹ - FoundationPoseï¼ˆCVPR 2024ï¼‰ï¼š**

```bash
# å®‰è£…
git clone https://github.com/NVlabs/FoundationPose.git
cd FoundationPose
bash build_all.sh

# ä¸‹è½½é¢„è®­ç»ƒæƒé‡
wget https://huggingface.co/wenbowen/foundationpose/resolve/main/model.pth
```

```python
# è¿è¡Œä½å§¿ä¼°è®¡
import numpy as np
import torch
from foundationpose.estimater import FoundationPose

# åˆå§‹åŒ–
estimater = FoundationPose(
    model_path='model.pth',
    mesh_path='path/to/smt_0402.obj',  # ç‰©ä½“3Dæ¨¡å‹
    debug=2,
)

# è¯»å–RGB-Då›¾åƒ
color = cv2.imread('rgb.png')
depth = np.load('depth.npy')

# ä¼°è®¡ä½å§¿
pose = estimater.register(
    K=camera_intrinsics,  # 3x3ç›¸æœºå†…å‚çŸ©é˜µ
    rgb=color,
    depth=depth,
    ob_mask=object_mask,  # ç‰©ä½“åˆ†å‰²mask
)

# è¾“å‡ºï¼š4x4å˜æ¢çŸ©é˜µ
print(f"ç‰©ä½“ä½å§¿ï¼š\n{pose}")
# [[R11, R12, R13, tx],
#  [R21, R22, R23, ty],
#  [R31, R32, R33, tz],
#  [0,   0,   0,   1 ]]
```

#### 2.1.3 ç‚¹äº‘å¤„ç†Pipeline

```python
import open3d as o3d
import numpy as np

class PointCloudProcessor:
    """3Cé›¶ä»¶ç‚¹äº‘å¤„ç†pipeline"""
    
    def __init__(self):
        self.voxel_size = 0.001  # 1mmä½“ç´ 
    
    def process(self, rgbd_image, camera_intrinsic):
        """å®Œæ•´å¤„ç†æµç¨‹"""
        # 1. RGB-Dè½¬ç‚¹äº‘
        pcd = o3d.geometry.PointCloud.create_from_rgbd_image(
            rgbd_image,
            camera_intrinsic,
        )
        
        # 2. é™å™ª
        pcd = self.remove_noise(pcd)
        
        # 3. å¹³é¢åˆ†å‰²ï¼ˆå»é™¤æ¡Œé¢ï¼‰
        pcd = self.remove_plane(pcd)
        
        # 4. èšç±»ï¼ˆåˆ†ç¦»å¤šä¸ªç‰©ä½“ï¼‰
        clusters = self.cluster_objects(pcd)
        
        return clusters
    
    def remove_noise(self, pcd):
        """ç»Ÿè®¡æ»¤æ³¢å»å™ª"""
        pcd, _ = pcd.remove_statistical_outlier(
            nb_neighbors=20,
            std_ratio=2.0,
        )
        return pcd
    
    def remove_plane(self, pcd):
        """RANSACå¹³é¢åˆ†å‰²"""
        plane_model, inliers = pcd.segment_plane(
            distance_threshold=0.005,  # 5mm
            ransac_n=3,
            num_iterations=1000,
        )
        # è¿”å›éå¹³é¢ç‚¹ï¼ˆç‰©ä½“ï¼‰
        object_pcd = pcd.select_by_index(inliers, invert=True)
        return object_pcd
    
    def cluster_objects(self, pcd):
        """DBSCANèšç±»"""
        labels = np.array(pcd.cluster_dbscan(
            eps=0.01,  # 10mm
            min_points=10,
        ))
        
        # åˆ†ç¦»æ¯ä¸ªcluster
        max_label = labels.max()
        clusters = []
        for i in range(max_label + 1):
            cluster_indices = np.where(labels == i)[0]
            cluster_pcd = pcd.select_by_index(cluster_indices)
            clusters.append(cluster_pcd)
        
        return clusters
```

### 2.2 æŠ“å–è§„åˆ’ç®—æ³•

#### 2.2.1 åŸºäºå­¦ä¹ çš„æŠ“å–ç”Ÿæˆ

**æ¨èæ–¹æ³•ï¼š**

| æ–¹æ³• | ä»£ç ä»“åº“ | ç‰¹ç‚¹ | æ€§èƒ½æŒ‡æ ‡ |
|------|---------|------|---------|
| **GraspNet-1B** | `graspnet/graspnet-baseline` | å·¥ä¸šæ ‡å‡†baseline | 82.3% AP@0.8 |
| **AnyGrasp** | `graspnet/anygrasp_sdk` | SOTAæ€§èƒ½ | 92.7% æˆåŠŸç‡ @ 0.03s |
| **Contact-GraspNet** | `NVlabs/contact_graspnet` | ç²¾ç¡®æ¥è§¦ç‚¹ | 91.2% æˆåŠŸç‡ |
| **GraspNeRF** | `Ray3D/GraspNeRF` | å¤„ç†é€æ˜ç‰©ä½“ | 88% on transparent |

**å®ç° - AnyGraspï¼ˆæ¨èç”¨äºç”Ÿäº§ï¼‰ï¼š**

```bash
# 1. å®‰è£…
pip install anygrasp
# éœ€ç”³è¯·licenseï¼šhttps://graspnet.net/anygrasp.html
```

```python
# 2. ä½¿ç”¨AnyGraspç”ŸæˆæŠ“å–
from anygrasp import AnyGraspDetector
import numpy as np

# åˆå§‹åŒ–æ£€æµ‹å™¨
detector = AnyGraspDetector(
    cfgs_path='config.yaml',
    checkpoint_path='checkpoint.tar',
)

# è¾“å…¥ç‚¹äº‘ï¼ˆNx3æ•°ç»„ï¼‰
point_cloud = np.load('scene_pointcloud.npy')

# ç”ŸæˆæŠ“å–
grasps, scores = detector.predict(point_cloud)

# è¾“å‡ºæ ¼å¼ï¼š
# grasps: (N, 4, 4) - Nä¸ªæŠ“å–çš„4x4å˜æ¢çŸ©é˜µ
# scores: (N,) - æ¯ä¸ªæŠ“å–çš„ç½®ä¿¡åº¦åˆ†æ•°

# é€‰æ‹©æœ€ä½³æŠ“å–
best_grasp_idx = np.argmax(scores)
best_grasp = grasps[best_grasp_idx]

print(f"æœ€ä½³æŠ“å–ä½å§¿ï¼š\n{best_grasp}")
print(f"ç½®ä¿¡åº¦ï¼š{scores[best_grasp_idx]:.2f}")
```

**ä»å¤´è®­ç»ƒè‡ªå®šä¹‰æŠ“å–ç½‘ç»œï¼š**

```python
# åŸºäºGraspNet-1Bè®­ç»ƒè‡ªå®šä¹‰æ¨¡å‹
import torch
from graspnetAPI import GraspNet

# 1. åŠ è½½GraspNetæ•°æ®é›†
dataset = GraspNet(
    root='/path/to/graspnet',
    camera='realsense',
    split='train',
)

# 2. å®šä¹‰è®­ç»ƒå¾ªç¯
from graspnet_baseline import GraspNetModel

model = GraspNetModel(
    num_view=300,
    num_angle=12,
    num_depth=4,
    cylinder_radius=0.05,
    hmin=-0.02,
    hmax=0.08,
)

optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

for epoch in range(100):
    for batch in dataset:
        points = batch['point_clouds']  # (B, N, 3)
        grasp_labels = batch['grasp_labels']  # (B, ...)
        
        # å‰å‘ä¼ æ’­
        pred_grasps, pred_scores = model(points)
        
        # è®¡ç®—æŸå¤±
        loss = compute_grasp_loss(pred_grasps, pred_scores, grasp_labels)
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    
    print(f"Epoch {epoch}: Loss = {loss.item():.4f}")
```

#### 2.2.2 æŠ“å–è´¨é‡è¯„ä¼°

```python
class GraspQualityEvaluator:
    """æŠ“å–è´¨é‡è¯„ä¼°å™¨"""
    
    def evaluate(self, grasp_pose, object_mesh):
        """
        è¯„ä¼°æŠ“å–è´¨é‡
        
        Args:
            grasp_pose: 4x4æŠ“å–ä½å§¿çŸ©é˜µ
            object_mesh: trimesh.Trimeshç‰©ä½“æ¨¡å‹
        
        Returns:
            quality_score: 0-1ä¹‹é—´çš„è´¨é‡åˆ†æ•°
        """
        scores = {}
        
        # 1. åŠ›é—­åŒ…æ£€æŸ¥
        scores['force_closure'] = self.check_force_closure(grasp_pose, object_mesh)
        
        # 2. é˜²ç¢°æ’æ£€æŸ¥
        scores['collision_free'] = self.check_collision(grasp_pose, object_mesh)
        
        # 3. æŠ“å–ç¨³å®šæ€§
        scores['stability'] = self.compute_stability(grasp_pose, object_mesh)
        
        # 4. å¯è¾¾æ€§
        scores['reachability'] = self.check_reachability(grasp_pose)
        
        # åŠ æƒæ±‚å’Œ
        weights = {
            'force_closure': 0.4,
            'collision_free': 0.3,
            'stability': 0.2,
            'reachability': 0.1,
        }
        
        total_score = sum(scores[k] * weights[k] for k in weights)
        return total_score, scores
    
    def check_force_closure(self, grasp_pose, object_mesh):
        """æ£€æŸ¥åŠ›é—­åŒ…ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        # è·å–æ¥è§¦ç‚¹
        contact_points = self.get_contact_points(grasp_pose, object_mesh)
        
        if len(contact_points) < 2:
            return 0.0
        
        # è®¡ç®—æ¥è§¦ç‚¹æ³•å‘é‡
        normals = self.compute_contact_normals(contact_points, object_mesh)
        
        # æ£€æŸ¥æ³•å‘é‡æ˜¯å¦ç›¸å¯¹
        angle = np.arccos(np.dot(normals[0], -normals[1]))
        
        # æ¥è¿‘180åº¦å¾—åˆ†é«˜
        score = 1.0 - abs(angle - np.pi) / np.pi
        return score
    
    def check_collision(self, grasp_pose, object_mesh):
        """ç¢°æ’æ£€æµ‹"""
        import trimesh
        
        # åŠ è½½å¤¹çˆªæ¨¡å‹
        gripper_mesh = trimesh.load('gripper.obj')
        
        # å˜æ¢åˆ°æŠ“å–ä½å§¿
        gripper_mesh.apply_transform(grasp_pose)
        
        # æ£€æŸ¥ç¢°æ’
        collision_manager = trimesh.collision.CollisionManager()
        collision_manager.add_object('gripper', gripper_mesh)
        collision_manager.add_object('object', object_mesh)
        
        is_collision = collision_manager.in_collision_internal()
        
        return 0.0 if is_collision else 1.0
```

### 2.3 è¿åŠ¨è§„åˆ’ç®—æ³•

#### 2.3.1 MoveIt 2é…ç½®

```bash
# å®‰è£…MoveIt 2
sudo apt install ros-humble-moveit

# åˆ›å»ºMoveIté…ç½®ï¼ˆä»¥UR5ä¸ºä¾‹ï¼‰
ros2 launch moveit_setup_assistant setup_assistant.launch.py
```

**Pythonæ¥å£ä½¿ç”¨ï¼š**

```python
import rclpy
from moveit_msgs.msg import MoveItErrorCodes
from moveit_py import MoveItPy

class GraspPlanner:
    def __init__(self):
        rclpy.init()
        self.moveit = MoveItPy(node_name="grasp_planner")
        
        self.arm = self.moveit.get_planning_component("manipulator")
        self.gripper = self.moveit.get_planning_component("gripper")
    
    def plan_grasp(self, target_pose):
        """è§„åˆ’æŠ“å–è¿åŠ¨"""
        # 1. ç§»åŠ¨åˆ°é¢„æŠ“å–ä½ç½®ï¼ˆç›®æ ‡ä¸Šæ–¹10cmï¼‰
        pre_grasp_pose = target_pose.copy()
        pre_grasp_pose[2, 3] += 0.1  # Zè½´ä¸Šç§»10cm
        
        self.arm.set_goal_state(pose=pre_grasp_pose)
        plan1 = self.arm.plan()
        
        if plan1.error_code != MoveItErrorCodes.SUCCESS:
            print("é¢„æŠ“å–è§„åˆ’å¤±è´¥ï¼")
            return None
        
        # 2. æ‰“å¼€å¤¹çˆª
        self.gripper.set_named_target("open")
        plan2 = self.gripper.plan()
        
        # 3. ä¸‹é™åˆ°æŠ“å–ä½ç½®
        self.arm.set_goal_state(pose=target_pose)
        plan3 = self.arm.plan()
        
        # 4. é—­åˆå¤¹çˆª
        self.gripper.set_named_target("close")
        plan4 = self.gripper.plan()
        
        # 5. æå‡ç‰©ä½“
        lift_pose = target_pose.copy()
        lift_pose[2, 3] += 0.15
        self.arm.set_goal_state(pose=lift_pose)
        plan5 = self.arm.plan()
        
        # 6. æ‰§è¡Œæ‰€æœ‰æ­¥éª¤
        plans = [plan1, plan2, plan3, plan4, plan5]
        for i, plan in enumerate(plans):
            print(f"æ‰§è¡Œæ­¥éª¤ {i+1}/5...")
            self.arm.execute(plan)
        
        return True
```

#### 2.3.2 ç¢°æ’é¿éšœ

```python
from moveit_msgs.msg import PlanningScene, CollisionObject
from shape_msgs.msg import SolidPrimitive
from geometry_msgs.msg import Pose

class CollisionSceneManager:
    """ç®¡ç†ç¢°æ’åœºæ™¯"""
    
    def __init__(self, moveit_py):
        self.moveit = moveit_py
        self.planning_scene = self.moveit.get_planning_scene()
    
    def add_table(self, height=0.025):
        """æ·»åŠ å·¥ä½œå°"""
        table = CollisionObject()
        table.id = "table"
        table.header.frame_id = "world"
        
        # å®šä¹‰box
        box = SolidPrimitive()
        box.type = SolidPrimitive.BOX
        box.dimensions = [0.8, 0.8, height]
        
        # ä½ç½®
        pose = Pose()
        pose.position.z = height / 2
        pose.orientation.w = 1.0
        
        table.primitives.append(box)
        table.primitive_poses.append(pose)
        
        # æ·»åŠ åˆ°åœºæ™¯
        self.planning_scene.add_object(table)
    
    def add_objects_from_perception(self, detected_objects):
        """ä»æ„ŸçŸ¥ç»“æœæ·»åŠ ç‰©ä½“"""
        for i, obj in enumerate(detected_objects):
            collision_obj = CollisionObject()
            collision_obj.id = f"object_{i}"
            collision_obj.header.frame_id = "world"
            
            # ä½¿ç”¨mesh
            collision_obj.meshes.append(obj.mesh)
            collision_obj.mesh_poses.append(obj.pose)
            
            self.planning_scene.add_object(collision_obj)
```

### 2.4 å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼ˆé«˜çº§ï¼‰

#### 2.4.1 Isaac Lab + RLæ¡†æ¶

```python
# ä½¿ç”¨Isaac Labè®­ç»ƒæŠ“å–ç­–ç•¥
from omni.isaac.lab_tasks.manipulation.lift import LiftEnvCfg
from omni.isaac.lab.envs import ManagerBasedRLEnv
from stable_baselines3 import PPO

# 1. é…ç½®ç¯å¢ƒ
env_cfg = LiftEnvCfg()
env_cfg.scene.num_envs = 4096  # GPUå¹¶è¡Œ
env = ManagerBasedRLEnv(cfg=env_cfg)

# 2. é…ç½®PPOç®—æ³•
model = PPO(
    "MlpPolicy",
    env,
    learning_rate=3e-4,
    n_steps=1024,
    batch_size=512,
    n_epochs=10,
    gamma=0.99,
    gae_lambda=0.95,
    clip_range=0.2,
    verbose=1,
    tensorboard_log="./ppo_grasp_logs/",
)

# 3. è®­ç»ƒ
model.learn(
    total_timesteps=10_000_000,
    callback=checkpoint_callback,
)

# 4. ä¿å­˜æ¨¡å‹
model.save("ppo_grasp_policy")

# 5. æµ‹è¯•
obs, info = env.reset()
for _ in range(1000):
    action, _states = model.predict(obs, deterministic=True)
    obs, reward, terminated, truncated, info = env.step(action)
    
    if terminated or truncated:
        obs, info = env.reset()
```

#### 2.4.2 Domain Randomizationé…ç½®

```python
# Isaac Labä¸­çš„Domain Randomization
from omni.isaac.lab.utils import configclass
from omni.isaac.lab.managers import EventTermCfg as EventTerm

@configclass
class DomainRandomizationCfg:
    """é¢†åŸŸéšæœºåŒ–é…ç½®"""
    
    # 1. ç‰©ç†å‚æ•°éšæœºåŒ–
    randomize_object_mass = EventTerm(
        func=randomize_mass,
        params={"mass_range": (0.05, 0.5)},  # kg
        mode="startup",
    )
    
    randomize_friction = EventTerm(
        func=randomize_friction,
        params={"friction_range": (0.5, 1.5)},
        mode="startup",
    )
    
    # 2. è§†è§‰éšæœºåŒ–
    randomize_lighting = EventTerm(
        func=randomize_lights,
        params={
            "intensity_range": (500, 5000),  # lumens
            "color_temp_range": (2000, 6500),  # Kelvin
        },
        mode="interval",
        interval_range_s=(5.0, 10.0),
    )
    
    randomize_textures = EventTerm(
        func=randomize_textures,
        params={"texture_library": "textures/"},
        mode="reset",
    )
    
    # 3. å‡ ä½•éšæœºåŒ–
    randomize_object_scale = EventTerm(
        func=randomize_scale,
        params={"scale_range": (0.9, 1.1)},
        mode="reset",
    )
    
    randomize_object_pose = EventTerm(
        func=randomize_pose,
        params={
            "position_range": [(-0.3, 0.3), (-0.3, 0.3), (0.0, 0.1)],
            "orientation_range": [(0, 2*np.pi), (0, 0), (0, 0)],
        },
        mode="reset",
    )
```

---

## ğŸ”§ ç¬¬ä¸‰éƒ¨åˆ†ï¼šä»¿çœŸé›†æˆç¯èŠ‚

### 3.1 ç«¯åˆ°ç«¯ä»¿çœŸPipeline

```python
class GraspingSimulationPipeline:
    """å®Œæ•´æŠ“å–ä»¿çœŸPipeline"""
    
    def __init__(self, sim_platform='isaac_lab'):
        # åˆå§‹åŒ–å„æ¨¡å—
        self.perception = PerceptionModule()
        self.grasp_planner = GraspPlanningModule()
        self.motion_planner = MotionPlanningModule()
        self.controller = RobotController()
        
        # åˆå§‹åŒ–ä»¿çœŸç¯å¢ƒ
        if sim_platform == 'isaac_lab':
            self.sim = IsaacLabSimulation()
        elif sim_platform == 'mujoco':
            self.sim = MuJoCoSimulation()
        else:
            raise ValueError(f"Unsupported platform: {sim_platform}")
    
    def run_episode(self):
        """è¿è¡Œä¸€ä¸ªå®Œæ•´æŠ“å–episode"""
        # 1. é‡ç½®ç¯å¢ƒ
        obs = self.sim.reset()
        rgb_image = obs['camera']['rgb']
        depth_image = obs['camera']['depth']
        
        # 2. æ„ŸçŸ¥ï¼šæ£€æµ‹ç‰©ä½“
        detected_objects = self.perception.detect_objects(rgb_image, depth_image)
        
        if len(detected_objects) == 0:
            print("æœªæ£€æµ‹åˆ°ç‰©ä½“ï¼")
            return False
        
        # 3. é€‰æ‹©ç›®æ ‡ç‰©ä½“ï¼ˆæœ€è¿‘çš„ï¼‰
        target_object = self.select_target(detected_objects)
        
        # 4. ä¼°è®¡6Dä½å§¿
        object_pose = self.perception.estimate_pose(
            rgb_image, depth_image, target_object
        )
        
        # 5. ç”ŸæˆæŠ“å–
        grasps, scores = self.grasp_planner.generate_grasps(
            object_pose, target_object.model
        )
        best_grasp = grasps[np.argmax(scores)]
        
        # 6. è§„åˆ’è¿åŠ¨
        trajectory = self.motion_planner.plan_grasp_motion(
            current_pose=self.sim.get_robot_state(),
            grasp_pose=best_grasp,
        )
        
        if trajectory is None:
            print("è¿åŠ¨è§„åˆ’å¤±è´¥ï¼")
            return False
        
        # 7. æ‰§è¡Œè½¨è¿¹
        success = self.execute_trajectory(trajectory)
        
        # 8. è¯„ä¼°ç»“æœ
        is_grasped = self.check_grasp_success()
        
        return is_grasped
    
    def execute_trajectory(self, trajectory):
        """æ‰§è¡Œè½¨è¿¹"""
        for waypoint in trajectory:
            # è®¡ç®—å…³èŠ‚æ§åˆ¶æŒ‡ä»¤
            joint_targets = self.controller.compute_joint_targets(waypoint)
            
            # å‘é€åˆ°ä»¿çœŸå™¨
            self.sim.set_joint_targets(joint_targets)
            
            # æ­¥è¿›ä»¿çœŸ
            for _ in range(10):  # æ¯ä¸ªwaypointä»¿çœŸ10æ­¥
                self.sim.step()
        
        return True
    
    def check_grasp_success(self):
        """æ£€æŸ¥æŠ“å–æ˜¯å¦æˆåŠŸ"""
        # æå‡å¤¹çˆª
        self.sim.lift_gripper(height=0.1)
        
        # æ£€æŸ¥ç‰©ä½“æ˜¯å¦è·Ÿéš
        object_height = self.sim.get_object_height()
        
        return object_height > 0.05  # ç‰©ä½“æŠ¬èµ·5cmä»¥ä¸Š
```

### 3.2 æ•°æ®é‡‡é›†ä¸è®°å½•

#### 3.2.1 ROS 2 Bagå½•åˆ¶

```python
import rclpy
from rclpy.node import Node
from rosbag2_py import SequentialWriter, StorageOptions, ConverterOptions

class DataRecorder(Node):
    """ROS 2æ•°æ®è®°å½•å™¨"""
    
    def __init__(self):
        super().__init__('data_recorder')
        
        # é…ç½®bag writer
        storage_options = StorageOptions(
            uri='grasp_data',
            storage_id='sqlite3',
        )
        converter_options = ConverterOptions(
            input_serialization_format='cdr',
            output_serialization_format='cdr',
        )
        
        self.writer = SequentialWriter()
        self.writer.open(storage_options, converter_options)
        
        # è®¢é˜…è¯é¢˜
        self.create_subscription(
            Image, '/camera/rgb/image_raw', self.rgb_callback, 10
        )
        self.create_subscription(
            Image, '/camera/depth/image_raw', self.depth_callback, 10
        )
        self.create_subscription(
            JointState, '/joint_states', self.joint_callback, 10
        )
    
    def rgb_callback(self, msg):
        self.writer.write('/camera/rgb/image_raw', serialize_message(msg), self.get_clock().now().nanoseconds)
    
    # ... å…¶ä»–å›è°ƒå‡½æ•°
```

#### 3.2.2 è‡ªå®šä¹‰æ•°æ®æ ¼å¼

```python
import h5py
import numpy as np

class GraspDataset:
    """è‡ªå®šä¹‰æŠ“å–æ•°æ®é›†æ ¼å¼"""
    
    def __init__(self, filename):
        self.file = h5py.File(filename, 'w')
        
        # åˆ›å»ºæ•°æ®ç»„
        self.file.create_group('episodes')
        self.current_episode = 0
    
    def save_episode(self, episode_data):
        """
        ä¿å­˜ä¸€ä¸ªepisodeçš„æ•°æ®
        
        episode_data: {
            'rgb_images': (T, H, W, 3),
            'depth_images': (T, H, W),
            'joint_states': (T, 6),
            'gripper_states': (T, 1),
            'grasp_pose': (4, 4),
            'success': bool,
        }
        """
        ep_group = self.file['episodes'].create_group(f'ep_{self.current_episode}')
        
        for key, value in episode_data.items():
            ep_group.create_dataset(key, data=value, compression='gzip')
        
        self.current_episode += 1
    
    def close(self):
        self.file.close()

# ä½¿ç”¨ç¤ºä¾‹
dataset = GraspDataset('grasp_dataset.h5')

for i in range(1000):
    episode_data = run_grasp_episode()
    dataset.save_episode(episode_data)

dataset.close()
```

### 3.3 æ€§èƒ½è¯„ä¼°å·¥å…·

```python
class GraspingBenchmark:
    """æŠ“å–ç³»ç»Ÿæ€§èƒ½è¯„ä¼°"""
    
    def __init__(self):
        self.metrics = {
            'success_rate': [],
            'grasp_time': [],
            'planning_time': [],
            'execution_time': [],
            'collision_count': [],
        }
    
    def run_benchmark(self, pipeline, num_episodes=100):
        """è¿è¡Œbenchmark"""
        print(f"è¿è¡Œ{num_episodes}æ¬¡æŠ“å–æµ‹è¯•...")
        
        for i in range(num_episodes):
            start_time = time.time()
            
            # è¿è¡ŒæŠ“å–
            result = pipeline.run_episode()
            
            end_time = time.time()
            
            # è®°å½•æŒ‡æ ‡
            self.metrics['success_rate'].append(1.0 if result['success'] else 0.0)
            self.metrics['grasp_time'].append(end_time - start_time)
            self.metrics['planning_time'].append(result['planning_time'])
            self.metrics['execution_time'].append(result['execution_time'])
            self.metrics['collision_count'].append(result['collisions'])
            
            if (i + 1) % 10 == 0:
                print(f"è¿›åº¦: {i+1}/{num_episodes}")
        
        # è®¡ç®—ç»Ÿè®¡ç»“æœ
        self.print_results()
    
    def print_results(self):
        """æ‰“å°benchmarkç»“æœ"""
        print("\n" + "="*50)
        print("Benchmark Results")
        print("="*50)
        
        print(f"æˆåŠŸç‡: {np.mean(self.metrics['success_rate']) * 100:.1f}%")
        print(f"å¹³å‡æŠ“å–æ—¶é—´: {np.mean(self.metrics['grasp_time']):.2f}s")
        print(f"å¹³å‡è§„åˆ’æ—¶é—´: {np.mean(self.metrics['planning_time']):.2f}s")
        print(f"å¹³å‡æ‰§è¡Œæ—¶é—´: {np.mean(self.metrics['execution_time']):.2f}s")
        print(f"å¹³å‡ç¢°æ’æ¬¡æ•°: {np.mean(self.metrics['collision_count']):.2f}")
        
        print("\n" + "="*50)
```

### 3.4 Sim2RealéªŒè¯

```python
class Sim2RealTransfer:
    """ä»¿çœŸåˆ°çœŸå®ç¯å¢ƒè¿ç§»"""
    
    def __init__(self, sim_env, real_env):
        self.sim_env = sim_env
        self.real_env = real_env
    
    def validate_transfer(self, policy, num_trials=50):
        """éªŒè¯Sim2Realè¿ç§»æ•ˆæœ"""
        sim_results = []
        real_results = []
        
        # 1. åœ¨ä»¿çœŸä¸­æµ‹è¯•
        print("åœ¨ä»¿çœŸç¯å¢ƒä¸­æµ‹è¯•...")
        for i in range(num_trials):
            obs = self.sim_env.reset()
            success = self.run_policy(policy, obs, self.sim_env)
            sim_results.append(success)
        
        # 2. åœ¨çœŸå®ç¯å¢ƒä¸­æµ‹è¯•
        print("åœ¨çœŸå®ç¯å¢ƒä¸­æµ‹è¯•...")
        for i in range(num_trials):
            obs = self.real_env.reset()
            success = self.run_policy(policy, obs, self.real_env)
            real_results.append(success)
        
        # 3. åˆ†æè¿ç§»gap
        sim_success_rate = np.mean(sim_results)
        real_success_rate = np.mean(real_results)
        transfer_gap = sim_success_rate - real_success_rate
        
        print(f"\nä»¿çœŸæˆåŠŸç‡: {sim_success_rate*100:.1f}%")
        print(f"çœŸå®æˆåŠŸç‡: {real_success_rate*100:.1f}%")
        print(f"è¿ç§»gap: {transfer_gap*100:.1f}%")
        
        # 4. åˆ†æå¤±è´¥åŸå› 
        self.analyze_failures(real_results)
        
        return {
            'sim_success_rate': sim_success_rate,
            'real_success_rate': real_success_rate,
            'transfer_gap': transfer_gap,
        }
    
    def analyze_failures(self, results):
        """åˆ†æå¤±è´¥åŸå› """
        # TODO: å®ç°å¤±è´¥åŸå› åˆ†ç±»
        pass
```

---

## ğŸ—ï¸ ç¬¬å››éƒ¨åˆ†ï¼šç³»ç»Ÿæ¶æ„ä¸æ‰©å±•

### 4.1 æ¨¡å—åŒ–ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Grasping System Architecture               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Perception  â”‚â”€â”€â”€â”€â”€â”€â”‚  Planning    â”‚â”€â”€â”€â”€â”€â”€â”‚ Control  â”‚  â”‚
â”‚  â”‚   Module     â”‚      â”‚   Module     â”‚      â”‚  Module  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                      â”‚                    â”‚       â”‚
â”‚         â”‚                      â”‚                    â”‚       â”‚
â”‚         â–¼                      â–¼                    â–¼       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚           Simulation / Real Robot Interface          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                      â”‚                    â”‚       â”‚
â”‚         â–¼                      â–¼                    â–¼       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Isaac Lab   â”‚      â”‚  MuJoCo     â”‚      â”‚Real Hardwareâ”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ¥å£å®šä¹‰ï¼š**

```python
from abc import ABC, abstractmethod

class PerceptionInterface(ABC):
    """æ„ŸçŸ¥æ¨¡å—æ¥å£"""
    
    @abstractmethod
    def detect_objects(self, rgb_image, depth_image):
        """æ£€æµ‹ç‰©ä½“"""
        pass
    
    @abstractmethod
    def estimate_pose(self, rgb_image, depth_image, object_mask):
        """ä¼°è®¡6Dä½å§¿"""
        pass

class PlanningInterface(ABC):
    """è§„åˆ’æ¨¡å—æ¥å£"""
    
    @abstractmethod
    def generate_grasps(self, object_pointcloud):
        """ç”ŸæˆæŠ“å–"""
        pass
    
    @abstractmethod
    def plan_motion(self, start_pose, goal_pose):
        """è§„åˆ’è¿åŠ¨"""
        pass

class ControlInterface(ABC):
    """æ§åˆ¶æ¨¡å—æ¥å£"""
    
    @abstractmethod
    def execute_trajectory(self, trajectory):
        """æ‰§è¡Œè½¨è¿¹"""
        pass
    
    @abstractmethod
    def get_robot_state(self):
        """è·å–æœºå™¨äººçŠ¶æ€"""
        pass
```

### 4.2 é…ç½®æ–‡ä»¶é©±åŠ¨

```yaml
# config/grasp_system.yaml
system:
  name: "3C Grasping System"
  version: "1.0"

simulation:
  platform: "isaac_lab"  # isaac_lab / mujoco / gazebo
  headless: false
  num_envs: 1
  
  scene:
    robot: "ur5e"
    gripper: "robotiq_2f85"
    camera: "realsense_d435i"
    objects:
      - type: "smt_0402"
        count: 20
      - type: "pcb_board"
        count: 5

perception:
  object_detection:
    model: "yolov8n"
    confidence_threshold: 0.5
    weights: "models/yolov8_3c.pt"
  
  pose_estimation:
    model: "foundationpose"
    weights: "models/foundationpose.pth"

planning:
  grasp_generation:
    model: "anygrasp"
    num_grasps: 100
    top_k: 10
  
  motion_planning:
    planner: "rrt_connect"
    planning_time: 5.0
    max_velocity_scaling: 0.5

control:
  joint_controller:
    type: "position"
    gains:
      kp: [100, 100, 100, 100, 100, 100]
      kd: [10, 10, 10, 10, 10, 10]

logging:
  level: "INFO"
  save_episodes: true
  output_dir: "logs/"
```

**åŠ è½½é…ç½®ï¼š**

```python
import yaml

class SystemConfig:
    def __init__(self, config_file):
        with open(config_file, 'r') as f:
            self.config = yaml.safe_load(f)
    
    def get(self, key_path):
        """è·å–åµŒå¥—é…ç½®å€¼ï¼Œå¦‚'simulation.platform'"""
        keys = key_path.split('.')
        value = self.config
        for key in keys:
            value = value[key]
        return value
    
    def set(self, key_path, new_value):
        """è®¾ç½®é…ç½®å€¼"""
        keys = key_path.split('.')
        value = self.config
        for key in keys[:-1]:
            value = value[key]
        value[keys[-1]] = new_value

# ä½¿ç”¨
config = SystemConfig('config/grasp_system.yaml')
platform = config.get('simulation.platform')
```

### 4.3 æ‰©å±•ç¤ºä¾‹

#### 4.3.1 æ·»åŠ æ–°çš„ç‰©ä½“æ£€æµ‹ç®—æ³•

```python
from perception import PerceptionInterface

class YOLOv10Detector(PerceptionInterface):
    """ä½¿ç”¨YOLOv10çš„æ£€æµ‹å™¨"""
    
    def __init__(self, weights_path):
        from ultralytics import YOLO
        self.model = YOLO(weights_path)
    
    def detect_objects(self, rgb_image, depth_image):
        results = self.model(rgb_image)
        
        detected_objects = []
        for result in results[0].boxes:
            obj = DetectedObject(
                class_id=int(result.cls),
                confidence=float(result.conf),
                bbox=result.xyxy[0].tolist(),
            )
            detected_objects.append(obj)
        
        return detected_objects
    
    def estimate_pose(self, rgb_image, depth_image, object_mask):
        # è°ƒç”¨ä½å§¿ä¼°è®¡ç®—æ³•
        return self.pose_estimator.estimate(rgb_image, depth_image, object_mask)

# æ³¨å†Œåˆ°ç³»ç»Ÿ
perception_registry = {
    'yolov8': YOLOv8Detector,
    'yolov10': YOLOv10Detector,
    'sam': SAMDetector,
}
```

#### 4.3.2 æ·»åŠ æ–°çš„ä»¿çœŸå¹³å°

```python
from simulation import SimulationInterface

class PyBulletSimulation(SimulationInterface):
    """PyBulletä»¿çœŸå®ç°"""
    
    def __init__(self, config):
        import pybullet as p
        self.p = p
        self.client = p.connect(p.GUI if not config['headless'] else p.DIRECT)
        
        # åŠ è½½åœºæ™¯
        self.load_scene(config)
    
    def reset(self):
        self.p.resetSimulation()
        self.load_scene(self.config)
        return self.get_observation()
    
    def step(self, action):
        # è®¾ç½®å…³èŠ‚ç›®æ ‡
        self.set_joint_targets(action)
        
        # æ­¥è¿›ä»¿çœŸ
        self.p.stepSimulation()
        
        # è·å–è§‚æµ‹
        obs = self.get_observation()
        reward = self.compute_reward()
        done = self.check_done()
        
        return obs, reward, done, {}
    
    # ... å®ç°å…¶ä»–æ¥å£æ–¹æ³•

# æ³¨å†Œ
simulation_registry = {
    'isaac_lab': IsaacLabSimulation,
    'mujoco': MuJoCoSimulation,
    'gazebo': GazeboSimulation,
    'pybullet': PyBulletSimulation,
}
```

---

## ğŸ“Š ç¬¬äº”éƒ¨åˆ†ï¼šå®Œæ•´ç¤ºä¾‹é¡¹ç›®

### 5.1 å¿«é€Ÿå¯åŠ¨é¡¹ç›®

```bash
# é¡¹ç›®ç»“æ„
3c_grasping_project/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ grasp_system.yaml
â”‚   â””â”€â”€ robot_ur5e.yaml
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ yolov8_3c.pt
â”‚   â”œâ”€â”€ anygrasp.tar
â”‚   â””â”€â”€ foundationpose.pth
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ robots/
â”‚   â”‚   â”œâ”€â”€ ur5e.urdf
â”‚   â”‚   â””â”€â”€ robotiq_2f85.urdf
â”‚   â””â”€â”€ objects/
â”‚       â”œâ”€â”€ smt_0402.obj
â”‚       â””â”€â”€ pcb_board.obj
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ perception/
â”‚   â”œâ”€â”€ planning/
â”‚   â”œâ”€â”€ control/
â”‚   â””â”€â”€ simulation/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ deploy.py
â”œâ”€â”€ tests/
â””â”€â”€ requirements.txt
```

**requirements.txtï¼š**

```txt
# ä»¿çœŸ
isaaclab>=1.0.0
mujoco>=3.0.0
pybullet>=3.2.5

# æœºå™¨äºº
moveit-py>=2.5.0

# æ„ŸçŸ¥
ultralytics>=8.0.0
open3d>=0.18.0
opencv-python>=4.8.0

# è§„åˆ’
torch>=2.0.0
numpy>=1.24.0
trimesh>=4.0.0

# å¼ºåŒ–å­¦ä¹ 
stable-baselines3>=2.0.0
gymnasium>=0.29.0

# å·¥å…·
pyyaml>=6.0
h5py>=3.9.0
matplotlib>=3.7.0
```

### 5.2 å®Œæ•´è®­ç»ƒè„šæœ¬

```python
# scripts/train.py
import argparse
from src.system import GraspingSystem
from src.simulation import SimulationFactory
from src.config import SystemConfig

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--config', default='config/grasp_system.yaml')
    parser.add_argument('--mode', choices=['train', 'eval', 'demo'], default='train')
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    config = SystemConfig(args.config)
    
    # åˆ›å»ºä»¿çœŸç¯å¢ƒ
    sim = SimulationFactory.create(config.get('simulation.platform'), config)
    
    # åˆ›å»ºæŠ“å–ç³»ç»Ÿ
    system = GraspingSystem(config, sim)
    
    if args.mode == 'train':
        print("å¼€å§‹è®­ç»ƒ...")
        system.train(num_episodes=10000)
    
    elif args.mode == 'eval':
        print("å¼€å§‹è¯„ä¼°...")
        results = system.evaluate(num_episodes=100)
        print(f"æˆåŠŸç‡: {results['success_rate']*100:.1f}%")
    
    elif args.mode == 'demo':
        print("è¿è¡Œæ¼”ç¤º...")
        system.run_demo()

if __name__ == '__main__':
    main()
```

**è¿è¡Œå‘½ä»¤ï¼š**

```bash
# è®­ç»ƒ
python scripts/train.py --mode train

# è¯„ä¼°
python scripts/train.py --mode eval

# æ¼”ç¤º
python scripts/train.py --mode demo
```

---

## ğŸ“š ç¬¬å…­éƒ¨åˆ†ï¼šå­¦ä¹ èµ„æºä¸å‚è€ƒ

### 6.1 æ¨èå­¦ä¹ è·¯å¾„

**åˆçº§ï¼ˆ1-2ä¸ªæœˆï¼‰ï¼š**
1. å­¦ä¹ ROS 2åŸºç¡€
2. ç†Ÿæ‚‰ä¸€ä¸ªä»¿çœŸå¹³å°ï¼ˆIsaac Labæˆ–MuJoCoï¼‰
3. è¿è¡Œç°æˆçš„æŠ“å–demo

**ä¸­çº§ï¼ˆ2-3ä¸ªæœˆï¼‰ï¼š**
1. æ·±å…¥å­¦ä¹ ç‚¹äº‘å¤„ç†ï¼ˆOpen3Dï¼‰
2. è®­ç»ƒç›®æ ‡æ£€æµ‹æ¨¡å‹ï¼ˆYOLOv8ï¼‰
3. ä½¿ç”¨GraspNet-1Bæ•°æ®é›†

**é«˜çº§ï¼ˆ3-6ä¸ªæœˆï¼‰ï¼š**
1. å®ç°è‡ªå®šä¹‰æŠ“å–ç®—æ³•
2. å¼ºåŒ–å­¦ä¹ è®­ç»ƒ
3. Sim2Realè¿ç§»

### 6.2 å…³é”®è®ºæ–‡

| è®ºæ–‡ | ä¼šè®®/æœŸåˆŠ | ä»£ç  |
|------|----------|------|
| GraspNet-1Billion | CVPR 2020 | github.com/graspnet/graspnet-baseline |
| AnyGrasp | T-RO 2023 | graspnet.net/anygrasp |
| Contact-GraspNet | ICRA 2021 | github.com/NVlabs/contact_graspnet |
| FoundationPose | CVPR 2024 | github.com/NVlabs/FoundationPose |
| Isaac Gym | CoRL 2021 | isaac-gym.github.io |

### 6.3 å¼€æºé¡¹ç›®å‚è€ƒ

| é¡¹ç›® | æè¿° | é“¾æ¥ |
|------|------|------|
| MoveIt 2 | ROSè¿åŠ¨è§„åˆ’æ¡†æ¶ | moveit.ros.org |
| Easy Manipulation Deployment | ç«¯åˆ°ç«¯æŠ“å–ç³»ç»Ÿ | github.com/ros-industrial/easy_manipulation_deployment |
| OpenManipulator-X | å¼€æºæœºæ¢°è‡‚ | github.com/ROBOTIS-GIT/open_manipulator |
| ROS Industrial | å·¥ä¸šæœºå™¨äººåŒ… | github.com/ros-industrial |

### 6.4 ç¤¾åŒºèµ„æº

- **è®ºå›ï¼š** ROS Discourse, Isaac Sim Forums
- **Slackï¼š** Open Robotics Slack
- **YouTubeï¼š** The Construct, Articulated Robotics
- **è¯¾ç¨‹ï¼š** Coursera "Modern Robotics", Udacity "Robotics ND"

---

## ğŸ¯ é™„å½•ï¼šå¿«é€Ÿæ£€æŸ¥æ¸…å•

### A. å¼€å‘ç¯å¢ƒæ£€æŸ¥

```bash
# 1. æ£€æŸ¥CUDA
nvidia-smi

# 2. æ£€æŸ¥ROS 2
ros2 --version

# 3. æ£€æŸ¥PythonåŒ…
python -c "import torch; print(torch.cuda.is_available())"
python -c "import open3d; print(open3d.__version__)"

# 4. æµ‹è¯•Isaac Labï¼ˆå¦‚ä½¿ç”¨ï¼‰
cd IsaacLab
./isaaclab.sh -p source/standalone/tutorials/00_sim/create_empty.py
```

### B. èµ„æºä¸‹è½½æ¸…å•

- [ ] UR5/UR5e URDFæ¨¡å‹
- [ ] Franka Panda URDFæ¨¡å‹
- [ ] Robotiqå¤¹çˆªæ¨¡å‹
- [ ] YCBç‰©ä½“æ•°æ®é›†ï¼ˆéƒ¨åˆ†ï¼‰
- [ ] GraspNet-1Bæ•°æ®é›†ï¼ˆæ³¨å†Œï¼‰
- [ ] YOLOv8é¢„è®­ç»ƒæƒé‡
- [ ] AnyGraspæ¨¡å‹ï¼ˆéœ€licenseï¼‰

### C. æ€§èƒ½ç›®æ ‡

| æŒ‡æ ‡ | ç ”å‘é˜¶æ®µç›®æ ‡ | ç”Ÿäº§é˜¶æ®µç›®æ ‡ |
|------|------------|------------|
| ä»¿çœŸæˆåŠŸç‡ | â‰¥85% | â‰¥92% |
| çœŸå®æˆåŠŸç‡ | â‰¥70% | â‰¥85% |
| æŠ“å–å‘¨æœŸ | â‰¤5s | â‰¤2s |
| æ„ŸçŸ¥å»¶è¿Ÿ | â‰¤200ms | â‰¤100ms |
| è§„åˆ’æ—¶é—´ | â‰¤1s | â‰¤500ms |

---

## ğŸ“§ æŠ€æœ¯æ”¯æŒ

**æ–‡æ¡£æ›´æ–°ï¼š** 2025-10-09  
**ç‰ˆæœ¬ï¼š** v1.0  

**åç»­æ›´æ–°è®¡åˆ’ï¼š**
- [ ] æ·»åŠ æŸ”æ€§ç‰©ä½“æŠ“å–ä¸“é¢˜
- [ ] æ·»åŠ åŒè‡‚åä½œæ¡ˆä¾‹
- [ ] æ·»åŠ è§¦è§‰ä¼ æ„Ÿå™¨é›†æˆ
- [ ] æ·»åŠ äº‘ç«¯è®­ç»ƒæ–¹æ¡ˆ

---

**ğŸ‰ ç°åœ¨æ‚¨å¯ä»¥å¼€å§‹æ„å»ºè‡ªå·±çš„æœºæ¢°è‡‚æŠ“å–ç³»ç»Ÿäº†ï¼**

å»ºè®®ä»ä»¥ä¸‹æ­¥éª¤å¼€å§‹ï¼š
1. å®‰è£…Isaac Labæˆ–MuJoCoï¼ˆé€‰ä¸€ä¸ªï¼‰
2. ä¸‹è½½UR5 URDFæ¨¡å‹
3. è¿è¡Œç¬¬ä¸€ä¸ªä»¿çœŸdemo
4. é€æ­¥é›†æˆå„ä¸ªæ¨¡å—

ç¥ç ”å‘é¡ºåˆ©ï¼ğŸš€

